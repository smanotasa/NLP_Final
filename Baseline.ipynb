{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#tools for baseline\n",
    "import re\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from tqdm import tqdm \n",
    "\n",
    "#visualize\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# modeling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "#\n",
    "SEED=420\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading the data \n",
    "train_data = pd.read_csv('Datasets/train.csv').sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "test_data = pd.read_csv('Datasets/test.csv').sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "unsupervised_data = pd.read_csv('Datasets/unsupervised.csv').sample(frac=1, random_state=SEED).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing ans splitting train data\n",
    "print(train_data.head())\n",
    "X_train = train_data['text']\n",
    "y_train = train_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing ans splitting test data\n",
    "print(test_data.head())\n",
    "X_test = test_data['text']\n",
    "y_test = test_data['label']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Baseline Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Dictionary with TF-IDF\n",
    "\n",
    "We perfomed text vectorization using TF-IDF (Term Frequency-Inverse Document Frequency) to convert the collection of reviews into a matrix of TF-IDF features. The resulting feature matrix will be then used to train the baseline models for text classification. \n",
    "\n",
    "The code separates the positive and negative reviews from the training set and applies the vectorization to each of them separately, resulting in two dataframes. We decided to include the m50 most frecuent words in each of the dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining base dictionaries as starters\n",
    "dict_pos = ['incredible', 'good', 'i love', \n",
    "                   'i like', 'awesome',\n",
    "                   'great', 'fantastic', \n",
    "                   'excellent', 'brillant',\n",
    "                   'genius', 'applause', \n",
    "                   'well done']\n",
    "\n",
    "dict_neg = ['awful', 'bad', 'i hate', \n",
    "                  \"i don't like\", 'worst', \n",
    "                  'horrible', 'dreadful', \n",
    "                  'terrible', 'poor', 'boring',\n",
    "                  'weak script', 'not funny',\n",
    "                  'rubbish', 'pointless', 'crap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing poitive and negative data \n",
    "train_pos = train_data[train_data['label'] == 1].reset_index(drop=True)\n",
    "train_neg = train_data[train_data['label'] == 0].reset_index(drop=True)\n",
    "\n",
    "X_train_pos = train_pos['text']\n",
    "y_train_pos = train_pos['label']\n",
    "X_train_neg = train_neg['text']\n",
    "y_train_neg = train_neg['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=50,ngram_range=(1,2), min_df=5, stop_words='english')\n",
    "\n",
    "#Positive values\n",
    "X_pos = vectorizer.fit_transform(X_train_pos)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense_pos = X_pos.todense()\n",
    "denselist_pos = dense_pos.tolist()\n",
    "df_pos = pd.DataFrame(denselist_pos, columns=feature_names)\n",
    "\n",
    "#Negative values\n",
    "X_neg = vectorizer.fit_transform(X_train_neg)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "dense_neg = X_neg.todense()\n",
    "denselist_neg = dense_neg.tolist()\n",
    "df_neg = pd.DataFrame(denselist_neg, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New words for the dictionary\n",
    "new_words_pos = df_pos.columns.tolist()\n",
    "new_words_neg = df_neg.columns.tolist()\n",
    "\n",
    "#Adding new words to old dictionaries\n",
    "dict_pos_new = dict_pos\n",
    "dict_neg_new = dict_neg\n",
    "\n",
    "dict_pos_new.extend(new_words_pos)\n",
    "dict_neg_new.extend(new_words_neg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Regex model\n",
    "\n",
    "As a first baseline, we used the previously created dictioary and a model using regexes. We used regular expressions to count the number of times the words in the dictionaries appear in the texts, and then labeled the texts as either positive or negative based on the relative frequency of positive and negative words in the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 71.31\n",
      "Recall: 73.22\n",
      "F1: 72.25\n"
     ]
    }
   ],
   "source": [
    "def get_metrics(y_trues, y_preds, verbose=True):\n",
    "\n",
    "  recall = recall_score(y_trues, y_preds) * 100\n",
    "  precision = precision_score(y_trues, y_preds) * 100\n",
    "  f1 = f1_score(y_trues, y_preds) * 100\n",
    "\n",
    "  if verbose:\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1: {f1:.2f}')\n",
    "\n",
    "  return recall, precision, f1\n",
    "\n",
    "def get_outputs(texts, dictionary):\n",
    "  \"\"\"\n",
    "  Objective: from the texts and a dictionnary of inputs, outputs 0 or 1\n",
    "\n",
    "  Inputs:\n",
    "    - texts, list: the list of texts\n",
    "    - dictionary, dict or list: the list of words that should output the number of words in the texts\n",
    "  Outputs:\n",
    "    - ouptuts, list: counts of the dicitonary's words in the texts\n",
    "  \"\"\"\n",
    "  outputs = []\n",
    "  for text in texts:\n",
    "    founds = re.findall(r'\\b(?:{})\\b'.format('|'.join(dictionary)), text)\n",
    "    n = len(founds)\n",
    "    outputs.append(n)\n",
    "\n",
    "  return outputs\n",
    "\n",
    "\n",
    "def get_final_outputs(positive_outputs, negative_outputs):\n",
    "  \"\"\"\n",
    "  Objective: decision function of the two labeling functions for positive and negative\n",
    "\n",
    "  Inputs:\n",
    "    - positive_outputs, list: the list of outputs for the positive dictionary\n",
    "    - negative_outputs; list: the list of outputs for the negative dictionary\n",
    "  Outputs:\n",
    "    - outputs, list: the same shape of inputs, that gives 1, 0 or -1 if does not know\n",
    "  \"\"\"\n",
    "  assert len(positive_outputs) == len(negative_outputs), 'ValueError: both lists should have the same size'\n",
    "  outputs = []\n",
    "  for pos, neg in zip(positive_outputs, negative_outputs):\n",
    "    if pos > neg:\n",
    "      outputs.append(1)\n",
    "    elif pos < neg:\n",
    "      outputs.append(0)\n",
    "    else:\n",
    "      outputs.append(-1)\n",
    "\n",
    "  return outputs\n",
    "\n",
    "def get_dictionary_metrics(my_texts, trues, good_dictionary, bad_dictionary,\n",
    "                           verbose=True):\n",
    "  \"\"\"\n",
    "  Objective: Automate the loop\n",
    "\n",
    "  Inputs:\n",
    "    - my_texts, list: the list of texts\n",
    "    - trues, np.array: the true outputs to look for\n",
    "    - positive_outputs, list: the list of outputs for the positive dictionary\n",
    "    - negative_outputs; list: the list of outputs for the negative dictionary\n",
    "    - verbose, boolean: display the metrics\n",
    "  Outputs:\n",
    "    - precision, float: precision score\n",
    "    - recall, float: recall score\n",
    "  \"\"\"\n",
    "  positive_outputs = get_outputs(my_texts, good_dictionary)\n",
    "  negative_outputs = get_outputs(my_texts, bad_dictionary)\n",
    "\n",
    "  outputs = np.array(get_final_outputs(positive_outputs, negative_outputs))\n",
    "  _outputs = outputs.copy()\n",
    "  outputs[outputs == -1] = 1 - trues[outputs == -1]\n",
    "  recall, precision, f1 = get_metrics(trues, outputs, verbose=verbose) \n",
    "\n",
    "  return _outputs\n",
    "\n",
    "final_outputs = get_dictionary_metrics(my_texts, trues, dict_pos_new, dict_neg_new)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Logistic regression\n",
    "\n",
    "Apart from the previos model, we wanted to explore which would be the results with a simple model like the logistic regression. We trained a logistic regression model with balanced class weights also using the TF-IDF representation of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 88.15\n",
      "Recall: 88.26\n",
      "F1: 88.21\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(class_weight='balanced', \n",
    "                         random_state=11, max_iter=1000)\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "y_preds = clf.predict(vectorizer.transform(X_test))\n",
    "r_tfidf = get_metrics(y_test, y_preds, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it performed pretty well, obtaining much better results as the Spacy rule based matching model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
